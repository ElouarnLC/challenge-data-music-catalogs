{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from reservoirpy.nodes import Reservoir, Ridge, ESN\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chemin vers la base de données SQLite\n",
    "# storage_url = \"sqlite:///db.sqlite3\"\n",
    "\n",
    "# # Charger l'étude existante\n",
    "# study = optuna.load_study(\n",
    "#     study_name=\"no-name-e82af600-5504-486b-95cb-12b9e9a1ded9\",  # Remplacer par le nom de votre étude\n",
    "#     storage=storage_url\n",
    "# )\n",
    "\n",
    "# # Récupérer les meilleurs paramètres\n",
    "# best_params = study.best_params\n",
    "# print(\"Meilleurs paramètres :\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "# EMBEDDING_SIZE = 256  # Taille des embeddings pour tous les inputs\n",
    "# NUM_HEADS = 8\n",
    "# NUM_LAYERS = 4\n",
    "# DROPOUT = 0.1\n",
    "# LEARNING_RATE = 1e-4\n",
    "# EPOCHS = 20\n",
    "# PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, num_heads, num_layers, num_labels, dropout\n",
    "    ):\n",
    "        super(MultiTaskTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, embedding_size)  # Embedding Layer\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embedding_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.classifier = nn.Linear(embedding_size, num_labels)  # Final Classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # Add a positional encoding (if needed)\n",
    "        embedded = embedded.unsqueeze(1)  # Add sequence dimension\n",
    "\n",
    "        # Transformer expects (batch, seq_len, embedding_size)\n",
    "        transformer_output = self.transformer(embedded, embedded)\n",
    "\n",
    "        # Take only the output of the first token (classification token equivalent)\n",
    "        output = transformer_output[:, 0, :]  # Extract first token\n",
    "\n",
    "        # Pass through the classifier\n",
    "        predictions = self.classifier(output)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    partOfData = 1\n",
    "    X_genres = pd.read_csv(\"../data/test/input_genres_tags_data.csv\")\n",
    "    X_instruments = pd.read_csv(\"../data/test/input_instruments_tags_data.csv\")\n",
    "    X_moods = pd.read_csv(\"../data/test/input_moods_tags_data.csv\")\n",
    "    X_genres_categories = pd.read_csv(\"../data/test/input_genres_categories_data.csv\")\n",
    "    X_instruments_categories = pd.read_csv(\n",
    "        \"../data/test/input_instruments_categories_data.csv\"\n",
    "    )\n",
    "    X_moods_categories = pd.read_csv(\"../data/test/input_moods_categories_data.csv\")\n",
    "\n",
    "    y_genres = pd.read_csv(\"../data/test/output_genres_tags_data.csv\")\n",
    "    y_instruments = pd.read_csv(\"../data/test/output_instruments_tags_data.csv\")\n",
    "    y_moods = pd.read_csv(\"../data/test/output_moods_tags_data.csv\")\n",
    "\n",
    "    # On peut garder seulement une partie des données\n",
    "    X_genres = X_genres[: int(partOfData * len(X_genres))]\n",
    "    X_instruments = X_instruments[: int(partOfData * len(X_instruments))]\n",
    "    X_moods = X_moods[: int(partOfData * len(X_moods))]\n",
    "    X_genres_categories = X_genres_categories[\n",
    "        : int(partOfData * len(X_genres_categories))\n",
    "    ]\n",
    "    X_instruments_categories = X_instruments_categories[\n",
    "        : int(partOfData * len(X_instruments_categories))\n",
    "    ]\n",
    "    X_moods_categories = X_moods_categories[: int(partOfData * len(X_moods_categories))]\n",
    "    y_genres = y_genres[: int(partOfData * len(y_genres))]\n",
    "    y_instruments = y_instruments[: int(partOfData * len(y_instruments))]\n",
    "    y_moods = y_moods[: int(partOfData * len(y_moods))]\n",
    "\n",
    "    return (\n",
    "        X_genres,\n",
    "        X_instruments,\n",
    "        X_moods,\n",
    "        X_genres_categories,\n",
    "        X_instruments_categories,\n",
    "        X_moods_categories,\n",
    "        y_genres,\n",
    "        y_instruments,\n",
    "        y_moods,\n",
    "    )\n",
    "\n",
    "\n",
    "# Ensure the input data is in the correct format\n",
    "def reshape_input(X):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return X.values.reshape(-1, 1, X.shape[1])  # Handles pandas DataFrame\n",
    "    elif isinstance(X, np.ndarray):\n",
    "        return X.reshape(-1, 1, X.shape[1])  # Handles numpy ndarray\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a pandas DataFrame or a numpy ndarray\")\n",
    "\n",
    "\n",
    "def format_predictions(predictions):\n",
    "    # Convert the list to a NumPy array\n",
    "    predictions_array = np.array(predictions)\n",
    "\n",
    "    # Reshape the array to 2-dimensional\n",
    "    predictions_reshaped = predictions_array.reshape(-1, predictions_array.shape[-1])\n",
    "\n",
    "    return predictions_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "(\n",
    "    X_genres,\n",
    "    X_instruments,\n",
    "    X_moods,\n",
    "    X_genres_categories,\n",
    "    X_instruments_categories,\n",
    "    X_moods_categories,\n",
    "    y_genres,\n",
    "    y_instruments,\n",
    "    y_moods,\n",
    ") = load_data()\n",
    "\n",
    "# Préparation des données\n",
    "X_genres = X_genres.drop(columns=[\"ChallengeID\"])\n",
    "X_instruments = X_instruments.drop(columns=[\"ChallengeID\"])\n",
    "X_moods = X_moods.drop(columns=[\"ChallengeID\"])\n",
    "X_genres_categories = X_genres_categories.drop(columns=[\"ChallengeID\"])\n",
    "X_instruments_categories = X_instruments_categories.drop(columns=[\"ChallengeID\"])\n",
    "X_moods_categories = X_moods_categories.drop(columns=[\"ChallengeID\"])\n",
    "y_genres = y_genres.drop(columns=[\"ChallengeID\"])\n",
    "y_instruments = y_instruments.drop(columns=[\"ChallengeID\"])\n",
    "y_moods = y_moods.drop(columns=[\"ChallengeID\"])\n",
    "\n",
    "\n",
    "X = np.concatenate(\n",
    "    [\n",
    "        X_genres,\n",
    "        X_instruments,\n",
    "        X_moods,\n",
    "        X_genres_categories,\n",
    "        X_instruments_categories,\n",
    "        X_moods_categories,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "y = np.concatenate([y_genres, y_instruments, y_moods], axis=1)\n",
    "\n",
    "# Convertir les données en tensors PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESNs models from ../models/model_5\n",
      "Nombre total de paramètres : 6866110\n"
     ]
    }
   ],
   "source": [
    "# Load ENSs models\n",
    "sub_folder = 0\n",
    "while os.path.exists(f\"../models/model_{sub_folder}\"):\n",
    "    sub_folder += 1\n",
    "sub_folder -= 1\n",
    "\n",
    "print(f\"Loading ESNs models from ../models/model_{sub_folder}\")\n",
    "\n",
    "with open(f\"../models/model_{sub_folder}/esn_Genre.pkl\", \"rb\") as f:\n",
    "    model_Genre = pickle.load(f)\n",
    "\n",
    "with open(f\"../models/model_{sub_folder}/esn_Instrument.pkl\", \"rb\") as f:\n",
    "    model_Instrument = pickle.load(f)\n",
    "\n",
    "with open(f\"../models/model_{sub_folder}/esn_Mood.pkl\", \"rb\") as f:\n",
    "    model_Mood = pickle.load(f)\n",
    "\n",
    "# Load Transformer model\n",
    "with open(f\"../models/model_{sub_folder}/transformer.pkl\", \"rb\") as f:\n",
    "    model_Transformer = pickle.load(f)\n",
    "\n",
    "# Affichage du nombre de paramètres\n",
    "print(\n",
    "    f\"Nombre total de paramètres : {sum(p.numel() for p in model_Transformer.parameters())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_genres_reshaped = reshape_input(X_genres)\n",
    "X_instruments_reshaped = reshape_input(X_instruments)\n",
    "X_moods_reshaped = reshape_input(X_moods)\n",
    "\n",
    "y_genres_reshaped = reshape_input(y_genres)\n",
    "y_instruments_reshaped = reshape_input(y_instruments)\n",
    "y_moods_reshaped = reshape_input(y_moods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ESN-0: 100%|██████████| 47615/47615 [00:02<00:00, 23169.94it/s]\n",
      "Running ESN-1: 100%|██████████| 47615/47615 [00:01<00:00, 33175.87it/s]\n",
      "Running ESN-2: 100%|██████████| 47615/47615 [00:01<00:00, 34502.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Obtenir les sorties des réservoirs\n",
    "y_genres_pred = model_Genre.run(X_genres_reshaped)\n",
    "y_instruments_pred = model_Instrument.run(X_instruments_reshaped)\n",
    "y_moods_pred = model_Mood.run(X_moods_reshaped)\n",
    "\n",
    "# Formater les prédictions\n",
    "y_genres_pred = format_predictions(y_genres_pred)\n",
    "y_instruments_pred = format_predictions(y_instruments_pred)\n",
    "y_moods_pred = format_predictions(y_moods_pred)\n",
    "\n",
    "\n",
    "# Combine toutes les sorties\n",
    "X_final = np.concatenate(\n",
    "    [\n",
    "        X_genres,\n",
    "        X_instruments,\n",
    "        X_moods,\n",
    "        y_genres_pred,\n",
    "        y_instruments_pred,\n",
    "        y_moods_pred,\n",
    "        X_genres_categories,\n",
    "        X_instruments_categories,\n",
    "        X_moods_categories,\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des datasets\n",
    "main_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_final, dtype=torch.float32).to(DEVICE),\n",
    "    y_tensor.clone().detach().to(DEVICE),\n",
    ")\n",
    "\n",
    "# Création des loaders\n",
    "main_loader = torch.utils.data.DataLoader(\n",
    "    main_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des performances (accuracy, precision, recall, f1-score)\n",
    "def evaluate_performance(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            predictions = model(X_batch)\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "            predictions = (predictions > 0.5).int()\n",
    "            y_true.append(y_batch.cpu().numpy())\n",
    "            y_pred.append(predictions.cpu().numpy())\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    # Save 5% of the rows of the predictions as csv files in the data folder in predictions folder with timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    np.savetxt(\n",
    "        f\"../data/predictions/test/y_true_{timestamp}.csv\",\n",
    "        y_true[: int(0.05 * len(y_true))],\n",
    "        delimiter=\",\",\n",
    "    )\n",
    "    np.savetxt(\n",
    "        f\"../data/predictions/test/y_pred_{timestamp}.csv\",\n",
    "        y_pred[: int(0.05 * len(y_pred))],\n",
    "        delimiter=\",\",\n",
    "    )\n",
    "\n",
    "    # Histograms plot of the predictions and true values for each tag\n",
    "    # for i in range(y_true.shape[1]):\n",
    "    #     plt.hist(y_true[:, i], bins=2, alpha=0.5, label=\"Benchmark\")\n",
    "    #     plt.hist(y_pred[:, i], bins=2, alpha=0.5, label=\"Predicted\")\n",
    "    #     plt.title(f\"Tag {i}\")\n",
    "    #     plt.legend()\n",
    "    #     plt.savefig(f\"../data/predictions/test/plots/histogram_tag_{i}.png\")\n",
    "    #     plt.clf()\n",
    "\n",
    "    y_true_total = np.sum(y_true, axis=1)\n",
    "    y_pred_total = np.sum(y_pred, axis=1)\n",
    "\n",
    "    plt.hist(y_true_total, bins=20, alpha=0.5, label=\"Benchmark\")\n",
    "    plt.hist(y_pred_total, bins=20, alpha=0.5, label=\"Predicted\")\n",
    "    plt.title(\"Total number of tags\")\n",
    "    plt.xlabel(\"Number of tags\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"../data/predictions/test/plots/histogram_total_tags.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    # Precision, Recall, F1-Score\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9912676609769895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0159    0.5000    0.0308         2\n",
      "           1     0.7452    0.7074    0.7258      1261\n",
      "           2     0.0000    0.0000    0.0000         0\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           4     0.1028    1.0000    0.1864        11\n",
      "           5     0.1879    0.8689    0.3090        61\n",
      "           6     0.1130    1.0000    0.2031        13\n",
      "           7     0.1375    0.9024    0.2387        41\n",
      "           8     0.4425    0.8597    0.5843       506\n",
      "           9     0.0984    1.0000    0.1791        24\n",
      "          10     0.8276    0.9421    0.8811      1243\n",
      "          11     0.8571    0.8774    0.8672      4226\n",
      "          12     0.3350    0.9273    0.4922       220\n",
      "          13     0.1816    0.8191    0.2973       188\n",
      "          14     0.1575    0.8833    0.2673       120\n",
      "          15     0.2273    0.9167    0.3642        60\n",
      "          16     0.0000    0.0000    0.0000         0\n",
      "          17     0.1394    0.8846    0.2408        26\n",
      "          18     0.0000    0.0000    0.0000         1\n",
      "          19     0.1333    0.4762    0.2083        21\n",
      "          20     0.7603    0.9472    0.8435      1306\n",
      "          21     0.2661    1.0000    0.4203        29\n",
      "          22     0.3028    0.9706    0.4615        34\n",
      "          23     0.5260    0.8726    0.6564       730\n",
      "          24     0.4514    0.9206    0.6057       504\n",
      "          25     0.0000    0.0000    0.0000         0\n",
      "          26     0.0926    0.7143    0.1639        14\n",
      "          27     0.5292    0.8914    0.6641      3213\n",
      "          28     0.8208    0.8669    0.8432      1427\n",
      "          29     0.2425    0.9496    0.3863       119\n",
      "          30     0.1277    1.0000    0.2264         6\n",
      "          31     0.0000    0.0000    0.0000         0\n",
      "          32     0.1562    1.0000    0.2703         5\n",
      "          33     0.7882    0.6213    0.6949       647\n",
      "          34     0.7560    0.8655    0.8071       290\n",
      "          35     0.6533    0.8219    0.7280       814\n",
      "          36     0.3875    0.8960    0.5410       298\n",
      "          37     0.0328    0.7857    0.0630        14\n",
      "          38     0.3194    0.5111    0.3932       135\n",
      "          39     0.6720    0.7146    0.6927      1293\n",
      "          40     0.0690    1.0000    0.1290         2\n",
      "          41     0.3140    0.7297    0.4390        37\n",
      "          42     0.0714    0.5000    0.1250        10\n",
      "          43     0.0000    0.0000    0.0000         0\n",
      "          44     0.0339    0.6667    0.0645         3\n",
      "          45     0.3509    0.8734    0.5006       229\n",
      "          46     0.0488    1.0000    0.0930         2\n",
      "          47     0.0370    1.0000    0.0714         1\n",
      "          48     0.5361    0.9541    0.6865       109\n",
      "          49     0.2632    0.8333    0.4000         6\n",
      "          50     0.0000    0.0000    0.0000         0\n",
      "          51     0.0000    0.0000    0.0000         0\n",
      "          52     0.0000    0.0000    0.0000         0\n",
      "          53     0.8981    0.9400    0.9186       300\n",
      "          54     0.1277    0.7895    0.2198        38\n",
      "          55     0.5158    0.7686    0.6173       255\n",
      "          56     0.0000    0.0000    0.0000         0\n",
      "          57     0.0000    0.0000    0.0000         0\n",
      "          58     0.0000    0.0000    0.0000         0\n",
      "          59     0.3562    1.0000    0.5253        78\n",
      "          60     0.0000    0.0000    0.0000         0\n",
      "          61     0.2740    0.9669    0.4270       121\n",
      "          62     0.0000    0.0000    0.0000         0\n",
      "          63     0.4074    0.8534    0.5515       116\n",
      "          64     0.1837    0.2308    0.2045        39\n",
      "          65     0.0549    0.7143    0.1020         7\n",
      "          66     0.5322    0.8727    0.6612       275\n",
      "          67     0.0208    0.4000    0.0396         5\n",
      "          68     0.2136    0.9565    0.3492        23\n",
      "          69     0.1939    0.9500    0.3220        20\n",
      "          70     0.2408    0.6667    0.3538        69\n",
      "          71     0.0000    0.0000    0.0000         0\n",
      "          72     0.0000    0.0000    0.0000         0\n",
      "          73     0.3864    0.9358    0.5469       109\n",
      "          74     0.0000    0.0000    0.0000         0\n",
      "          75     0.1667    1.0000    0.2857         1\n",
      "          76     0.0870    0.8000    0.1569         5\n",
      "          77     0.0783    0.9000    0.1440        10\n",
      "          78     0.0000    0.0000    0.0000         0\n",
      "          79     0.0132    1.0000    0.0260         1\n",
      "          80     0.2437    0.9355    0.3867        62\n",
      "          81     0.6353    0.8930    0.7424      1346\n",
      "          82     0.1011    1.0000    0.1836        19\n",
      "          83     0.3529    0.9000    0.5070        20\n",
      "          84     0.1369    0.9583    0.2396        24\n",
      "          85     0.0000    0.0000    0.0000         0\n",
      "          86     0.8060    0.8507    0.8277      1172\n",
      "          87     0.4440    0.8825    0.5908       485\n",
      "          88     0.0000    0.0000    0.0000         0\n",
      "          89     0.1439    0.8723    0.2470        47\n",
      "          90     0.9259    0.8224    0.8711       152\n",
      "          91     0.7500    0.9120    0.8231       523\n",
      "          92     0.8683    0.9180    0.8924      5595\n",
      "          93     0.4038    0.6562    0.5000       128\n",
      "          94     0.4640    0.9923    0.6324       130\n",
      "          95     0.8784    0.8306    0.8538      8587\n",
      "          96     0.4133    0.9394    0.5741        33\n",
      "          97     0.1383    1.0000    0.2430        13\n",
      "          98     0.1200    1.0000    0.2143         3\n",
      "          99     0.7849    0.8117    0.7981       409\n",
      "         100     0.8612    0.8393    0.8501      4419\n",
      "         101     0.4416    0.9810    0.6090       158\n",
      "         102     0.5802    0.8366    0.6852       955\n",
      "         103     0.0000    0.0000    0.0000         0\n",
      "         104     0.0000    0.0000    0.0000         0\n",
      "         105     0.1778    1.0000    0.3019         8\n",
      "         106     0.7858    0.8747    0.8279       495\n",
      "         107     0.6364    0.9211    0.7527       418\n",
      "         108     0.3000    0.7500    0.4286         4\n",
      "         109     0.1111    0.7895    0.1948        19\n",
      "         110     0.3429    0.8000    0.4800        15\n",
      "         111     0.0800    1.0000    0.1481         4\n",
      "         112     0.5091    0.7179    0.5957        39\n",
      "         113     0.6245    0.8571    0.7226       714\n",
      "         114     0.0667    1.0000    0.1250         1\n",
      "         115     0.9008    0.8259    0.8617      9555\n",
      "         116     0.7414    0.9374    0.8279      7125\n",
      "         117     0.0722    0.7778    0.1321         9\n",
      "         118     0.9397    0.8727    0.9049     12549\n",
      "         119     0.3176    0.9038    0.4700        52\n",
      "         120     0.3427    0.8167    0.4828        60\n",
      "         121     0.1765    1.0000    0.3000         3\n",
      "         122     0.8093    0.9578    0.8773      1919\n",
      "         123     0.1809    0.9231    0.3025        39\n",
      "         124     0.0000    0.0000    0.0000         0\n",
      "         125     0.6935    0.8832    0.7770       925\n",
      "         126     0.5581    0.9492    0.7029       354\n",
      "         127     0.2750    0.7333    0.4000        15\n",
      "         128     0.4342    0.9095    0.5877       232\n",
      "         129     0.3762    0.9360    0.5367       172\n",
      "         130     0.4314    0.9448    0.5923       163\n",
      "         131     0.4770    0.9828    0.6423       116\n",
      "         132     0.5869    0.8588    0.6972       354\n",
      "         133     0.4724    0.9872    0.6390        78\n",
      "         134     0.5312    0.7391    0.6182        23\n",
      "         135     0.7998    0.8039    0.8018       979\n",
      "         136     0.5556    0.6250    0.5882        40\n",
      "         137     0.6765    0.6053    0.6389        76\n",
      "         138     0.3502    0.8640    0.4984       272\n",
      "         139     0.2892    1.0000    0.4486        24\n",
      "         140     0.6076    0.9231    0.7328        52\n",
      "         141     0.8722    0.9278    0.8992      3229\n",
      "         142     0.3112    0.9104    0.4639        67\n",
      "         143     0.5820    0.8663    0.6963       172\n",
      "         144     0.5318    0.9099    0.6712       322\n",
      "         145     0.0000    0.0000    0.0000         0\n",
      "         146     0.3200    0.8889    0.4706         9\n",
      "         147     0.7931    0.9200    0.8519        25\n",
      "         148     0.6223    0.8603    0.7222       136\n",
      "         149     0.1494    0.9200    0.2570        25\n",
      "         150     0.6641    0.8763    0.7556       291\n",
      "         151     0.6889    1.0000    0.8158        31\n",
      "         152     0.0000    0.0000    0.0000         0\n",
      "         153     0.3232    1.0000    0.4885        32\n",
      "         154     0.2887    0.9438    0.4421        89\n",
      "         155     0.8042    0.9042    0.8513      8017\n",
      "         156     0.4000    0.8000    0.5333         5\n",
      "         157     0.8435    0.8378    0.8407       444\n",
      "         158     0.4001    0.8351    0.5410       746\n",
      "         159     0.6143    0.8958    0.7288       240\n",
      "         160     0.3667    0.9565    0.5301        23\n",
      "         161     0.9189    0.7386    0.8189      4648\n",
      "         162     0.6733    0.8712    0.7596       932\n",
      "         163     0.2174    1.0000    0.3571        10\n",
      "         164     0.1090    1.0000    0.1966        52\n",
      "         165     0.4815    0.9286    0.6341        28\n",
      "         166     0.4774    0.9867    0.6435        75\n",
      "         167     0.1638    0.9500    0.2794        20\n",
      "         168     0.3898    0.7931    0.5227        87\n",
      "         169     0.8546    0.9704    0.9088      1520\n",
      "         170     0.0000    0.0000    0.0000         0\n",
      "         171     0.0000    0.0000    0.0000         0\n",
      "         172     0.7888    0.8643    0.8248      5172\n",
      "         173     0.9121    0.7516    0.8241      2484\n",
      "         174     0.6746    0.8996    0.7710      1604\n",
      "         175     0.5763    0.9638    0.7213       995\n",
      "         176     0.0000    0.0000    0.0000         0\n",
      "         177     0.8319    0.9437    0.8843     11886\n",
      "         178     0.0000    0.0000    0.0000         0\n",
      "         179     0.6038    1.0000    0.7529        32\n",
      "         180     0.1283    0.9062    0.2248        32\n",
      "         181     0.4175    0.5972    0.4914        72\n",
      "         182     0.5483    0.8785    0.6752       181\n",
      "         183     0.6667    1.0000    0.8000         2\n",
      "         184     0.4773    0.7000    0.5676        30\n",
      "         185     0.4885    0.9140    0.6367       349\n",
      "         186     0.4217    0.8537    0.5645        41\n",
      "         187     0.0000    0.0000    0.0000         0\n",
      "         188     0.3417    0.9685    0.5051       127\n",
      "         189     0.8455    0.9083    0.8758       229\n",
      "         190     0.4167    0.8491    0.5590       106\n",
      "         191     0.1429    0.7500    0.2400         4\n",
      "         192     0.6593    0.9481    0.7778       790\n",
      "         193     0.8414    0.9879    0.9088      7583\n",
      "         194     0.0000    0.0000    0.0000         0\n",
      "         195     0.0000    0.0000    0.0000         0\n",
      "         196     0.3469    0.7727    0.4789        66\n",
      "         197     0.3684    0.9130    0.5250        23\n",
      "         198     0.7753    0.9452    0.8519       146\n",
      "         199     0.5437    0.8407    0.6603       496\n",
      "         200     0.1020    0.9091    0.1835        11\n",
      "         201     0.2420    0.9138    0.3827        58\n",
      "         202     0.2308    0.7215    0.3497        79\n",
      "         203     0.1210    0.9839    0.2155        62\n",
      "         204     0.6609    0.9129    0.7667      1136\n",
      "         205     0.5541    0.9634    0.7036      1722\n",
      "         206     0.3383    0.8071    0.4767       679\n",
      "         207     0.0000    0.0000    0.0000         0\n",
      "         208     0.5172    0.8959    0.6558      4486\n",
      "         209     0.3302    0.8525    0.4760       122\n",
      "         210     0.0102    1.0000    0.0201         2\n",
      "         211     0.5685    0.8478    0.6806      2872\n",
      "         212     0.6856    0.8663    0.7654       808\n",
      "         213     0.2154    0.9333    0.3500        15\n",
      "         214     0.0931    0.8529    0.1680       102\n",
      "         215     0.1333    1.0000    0.2353        28\n",
      "         216     0.2780    0.8011    0.4127       372\n",
      "         217     0.6040    0.8660    0.7116      2858\n",
      "         218     0.1321    0.9737    0.2327        38\n",
      "         219     0.3340    0.8655    0.4819       617\n",
      "         220     0.2086    0.9238    0.3404       105\n",
      "         221     0.0105    1.0000    0.0208         1\n",
      "         222     0.2357    0.9780    0.3799       409\n",
      "         223     0.3517    0.9490    0.5133       255\n",
      "         224     0.6810    0.7683    0.7220      1364\n",
      "         225     0.0077    1.0000    0.0153         1\n",
      "         226     0.0250    0.4000    0.0471         5\n",
      "         227     0.2566    0.8271    0.3917       295\n",
      "         228     0.6518    0.8790    0.7486      5272\n",
      "         229     0.5146    0.7077    0.5959      1047\n",
      "         230     0.0135    1.0000    0.0265         3\n",
      "         231     0.0270    1.0000    0.0526        10\n",
      "         232     0.0714    1.0000    0.1333        11\n",
      "         233     0.3163    0.8903    0.4667       957\n",
      "         234     0.6085    0.9168    0.7315      4519\n",
      "         235     0.5994    0.8617    0.7070      1960\n",
      "         236     0.4019    0.9531    0.5654       916\n",
      "         237     0.1981    0.9432    0.3274        88\n",
      "         238     0.0411    1.0000    0.0789        23\n",
      "         239     0.0000    0.0000    0.0000         0\n",
      "         240     0.5633    0.9906    0.7182      2339\n",
      "         241     0.0000    0.0000    0.0000         0\n",
      "         242     0.5055    0.9037    0.6483      1579\n",
      "         243     0.3775    0.9038    0.5325       738\n",
      "         244     0.0000    0.0000    0.0000         0\n",
      "         245     0.4517    0.8915    0.5996      1244\n",
      "         246     0.3151    0.7041    0.4353        98\n",
      "         247     0.4541    0.8248    0.5857      1410\n",
      "\n",
      "   micro avg     0.6542    0.8812    0.7509    176397\n",
      "   macro avg     0.3488    0.7433    0.4309    176397\n",
      "weighted avg     0.7326    0.8812    0.7852    176397\n",
      " samples avg     0.6459    0.8541    0.7075    176397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elouarn/Documents/Projet_IA/challenge-data-music-catalogs/music-catalogs-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/elouarn/Documents/Projet_IA/challenge-data-music-catalogs/music-catalogs-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/elouarn/Documents/Projet_IA/challenge-data-music-catalogs/music-catalogs-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/elouarn/Documents/Projet_IA/challenge-data-music-catalogs/music-catalogs-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/elouarn/Documents/Projet_IA/challenge-data-music-catalogs/music-catalogs-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/elouarn/Documents/Projet_IA/challenge-data-music-catalogs/music-catalogs-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation du modèle\n",
    "evaluate_performance(model_Transformer, main_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 1:\n",
      "  True Tags: drum-machine, electric-guitar, synthesizer, confident, driving\n",
      "  Predicted Tags: bass-guitar, drum-machine, electric-guitar, synthesizer, confident, driving, exciting, spectacular\n",
      "\n",
      "Song 2:\n",
      "  True Tags: \n",
      "  Predicted Tags: world\n",
      "\n",
      "Song 3:\n",
      "  True Tags: acoustic-guitar\n",
      "  Predicted Tags: lounge, acoustic-guitar, carefree, relaxed\n",
      "\n",
      "Song 4:\n",
      "  True Tags: vintage-jazz, male-vocals, vocal\n",
      "  Predicted Tags: vintage-jazz, acoustic-guitar, vocal, romantic, sad\n",
      "\n",
      "Song 5:\n",
      "  True Tags: strings-section, relaxed\n",
      "  Predicted Tags: strings-section, synth-pad, synthesizer, relaxed\n",
      "\n",
      "Song 6:\n",
      "  True Tags: sinister\n",
      "  Predicted Tags: vocal, sinister, suspenseful\n",
      "\n",
      "Song 7:\n",
      "  True Tags: acoustic-guitar, relaxed, romantic\n",
      "  Predicted Tags: vintage-jazz, acoustic-guitar, relaxed, romantic\n",
      "\n",
      "Song 8:\n",
      "  True Tags: drum-kit, piano, strings-section\n",
      "  Predicted Tags: piano, strings-section, hopeful, reflective, sad\n",
      "\n",
      "Song 9:\n",
      "  True Tags: contemporary-classical, symphony-orchestra, confident, epic, majestic\n",
      "  Predicted Tags: contemporary-classical, symphony-orchestra, confident, epic, inspirational\n",
      "\n",
      "Song 10:\n",
      "  True Tags: accordion\n",
      "  Predicted Tags: world, accordion, acoustic-guitar\n",
      "\n",
      "Song 11:\n",
      "  True Tags: contemporary-rnb, drum-machine, synthesizer\n",
      "  Predicted Tags: contemporary-rnb, drum-machine, synthesizer, vocal\n",
      "\n",
      "Song 12:\n",
      "  True Tags: chill-out, piano, strings-section, uplifting\n",
      "  Predicted Tags: chill-out, piano, strings-section, uplifting\n",
      "\n",
      "Song 13:\n",
      "  True Tags: acoustic-guitar, handclaps, happy, optimistic\n",
      "  Predicted Tags: acoustic-guitar, handclaps, happy, optimistic\n",
      "\n",
      "Song 14:\n",
      "  True Tags: synthesizer\n",
      "  Predicted Tags: fender-rhodes, synthesizer\n",
      "\n",
      "Song 15:\n",
      "  True Tags: contemporary-classical, piano, strings-section\n",
      "  Predicted Tags: contemporary-classical, piano, strings-section\n",
      "\n",
      "Song 16:\n",
      "  True Tags: classical, piano, solo\n",
      "  Predicted Tags: classical, piano, solo\n",
      "\n",
      "Song 17:\n",
      "  True Tags: double-bass\n",
      "  Predicted Tags: double-bass\n",
      "\n",
      "Song 18:\n",
      "  True Tags: electronica, drum-machine, synthesizer\n",
      "  Predicted Tags: electronica, house, drum-machine, synthesizer, optimistic\n",
      "\n",
      "Song 19:\n",
      "  True Tags: easy-listening, piano, solo, romantic\n",
      "  Predicted Tags: easy-listening, piano, solo, romantic\n",
      "\n",
      "Song 20:\n",
      "  True Tags: bass-guitar, drum-kit, electric-guitar, rock-band, sinister\n",
      "  Predicted Tags: hard-rock, bass-guitar, drum-kit, electric-guitar, rock-band, aggressive, anxious, hate, inspirational, sinister\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the tag correspondences\n",
    "tag_correspondences = pd.read_csv(\"../data/mewo-labels.csv\")\n",
    "\n",
    "# Load latest y_true and y_pred from test predictions folder\n",
    "# Get the latest timestamped files\n",
    "predictions_folder = \"../data/predictions/test/\"\n",
    "y_true_files = sorted(\n",
    "    [f for f in os.listdir(predictions_folder) if f.startswith(\"y_true_\")]\n",
    ")\n",
    "y_pred_files = sorted(\n",
    "    [f for f in os.listdir(predictions_folder) if f.startswith(\"y_pred_\")]\n",
    ")\n",
    "\n",
    "latest_y_true_file = y_true_files[-1]\n",
    "latest_y_pred_file = y_pred_files[-1]\n",
    "\n",
    "# Load the latest y_true and y_pred\n",
    "y_true = np.loadtxt(os.path.join(predictions_folder, latest_y_true_file), delimiter=\",\")\n",
    "y_pred = np.loadtxt(os.path.join(predictions_folder, latest_y_pred_file), delimiter=\",\")\n",
    "\n",
    "# Randomly select 20 songs\n",
    "num_songs = 20\n",
    "random_indices = np.random.choice(len(y_true), num_songs, replace=False)\n",
    "\n",
    "\n",
    "# Extract the true and predicted tags for these songs\n",
    "true_tags = y_true[random_indices]\n",
    "predicted_tags = y_pred[random_indices]\n",
    "\n",
    "# Map the tags to their names\n",
    "tag_names = tag_correspondences.columns[1:]  # Skip the first column which is not a tag\n",
    "\n",
    "# Display the true and predicted tags\n",
    "for i in range(num_songs):\n",
    "    true_tag_names = [\n",
    "        tag_names[j] for j in range(len(tag_names)) if true_tags[i][j] == 1\n",
    "    ]\n",
    "    predicted_tag_names = [\n",
    "        tag_names[j] for j in range(len(tag_names)) if predicted_tags[i][j] == 1\n",
    "    ]\n",
    "    print(f\"Song {i + 1}:\")\n",
    "    print(f\"  True Tags: {', '.join(true_tag_names)}\")\n",
    "    print(f\"  Predicted Tags: {', '.join(predicted_tag_names)}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
